#!/usr/bin/python3
from cmath import exp
from logging import NullHandler
from re import A, I
import sys
import shutil, os
import glob
import json
#from types import TracebackType
#from warnings import catch_warnings
from pathlib import Path
from tkinter.messagebox import NO
from astropy.io import fits
import subprocess
from numpy import append
import argparse

from sklearn.model_selection import GroupShuffleSplit
from sympy import N

#from sympy import appellf1, arg

class DefaultArgParser(argparse.ArgumentParser):
    def error(self, message):
        sys.stderr.write('error: %s\n' % message)
        self.print_help()
        sys.exit(2)

###########################################
def disp_help():
    print('display some help here!')

###########################################
def add_files(dir, files, super):
    print('### add ###')
    # read and collect all fits files in subdirectory of every filter

    dss_file_list = []
    dss_file_list_set = set(dss_file_list)

    with open('./config.json', 'r') as f:
        config = json.load(f)

    groups = []

    curdir = os.getcwd()

    for f in files:
        entry_found = False    
         
        path         = os.path.dirname(f)
        path, filter = os.path.split(path)
        path, imagetype = os.path.split(path)
        foldername   = os.path.basename(os.path.normpath(path))
        rel_filename = os.path.relpath(f, path)
        if rel_filename[0] != '.':
            rel_filename = os.path.join('.',rel_filename)

        if super == True:
            dss_file = foldername + '_' + 'SUPER'  + '.dssfilelist'
        else:
            dss_file = foldername + '_' + filter + '.dssfilelist'

        dss_file_path = os.path.join(path,dss_file)
        dss_file_folder = path

        os.chdir(dss_file_folder) #switch to make relative paths work
#        print(dss_file_folder)

        entry_found = False
        dark_cali_file = ''

        print(rel_filename)

        #read offset and gain from fits
        hdul = fits.open(f)
        gain   = hdul[0].header['GAIN']
        offset = hdul[0].header['OFFSET']
        exposure = hdul[0].header['EXPOSURE']
        if exposure == 0:
            exposure = hdul[0].header['EXPTIME']

        #search for correct flat and dark specified in config
        for dark in config['darks']:
            if dark['seconds'] == exposure and dark['gain'] == gain and dark['offset'] == offset:
                dark_cali_file = dark['location']
                try:
                    rel_dark_cali_file = os.path.relpath(dark_cali_file,dss_file_folder)                
                except ValueError:
                    rel_dark_cali_file = dark_cali_file

        for flat in config['flats']:
            if flat['filter'] == filter:
                flat_cali_file = flat['location']
                try:
                    rel_flat_cali_file = os.path.relpath(flat_cali_file,dss_file_folder)                
                except ValueError:
                    rel_flat_cali_file = flat_cali_file


        lines = []

        if os.path.exists(dss_file_path) == False:
            #create new empty dss default file
            lines.append('DSS file list\n')
            lines.append('CHECKED\tTYPE\tFILE\n')

            #add flats + darks
            if dark_cali_file != '':
                lines.append('1\tdark\t' + rel_dark_cali_file  + '\n')
            if flat_cali_file != '':
                lines.append('1\tflat\t' + rel_flat_cali_file + '\n')
            
            #add default config            
            if filter in ['Ha','Sii','Oiii']:
                lines.append(config['rgb_config'])
            else:
                lines.append(config['nb_config'])
            
            groups = []

            #build initial group
            if len(groups) == 0:
                group = {}
                group['id'] = '0'
                group['index'] = 1
                group['gain']  = gain
                group['offset'] = offset
                group['exposure'] = int(exposure)
                group['filter'] = filter
                groups.append(group)          

        else:
            #open existing dss list file
            with open(dss_file_path) as file:
                lines = file.readlines()


        if dss_file_path not in dss_file_list_set:
            dss_file_list_set.add(dss_file_path)
            dss_file_list.append(dss_file_path)


        # find other groups that are already in file
        new_group = {}
        new_group['index'] = 0
        for idx, line in enumerate(lines):

            if ( line[0] == '1' or line[0] == '0' ) and line[2] == 'l':
                # add info about exposure, gain and offset for group
                if new_group['index'] != 0:
                    hdul = fits.open(line[8:-1])
                    
                    new_group['gain']     = hdul[0].header['GAIN']
                    new_group['offset']   = hdul[0].header['OFFSET']
                    new_group['exposure'] = hdul[0].header['EXPOSURE']
                    new_group['filter']   = hdul[0].header['FILTER']

                    if not new_group in groups:
                        groups.append(new_group)
                        print(line)
                        print(new_group)
                    new_group = {}
                    new_group['index'] = 0
            elif ( line[0:9] == '#GROUPID#' ):
                # new group - details to be filled by first image
                new_group = {}
                new_group['id'] = line[9:10]
                new_group['index'] = idx
                new_group['gain']  = 0
                new_group['offset'] = 0
                new_group['exposure'] = 0
                new_group['filter'] = ''
            elif ( line[0:4] == '#WS#' ):
                last_line = idx
                # no more groups expected
                break        
        
        

        #search for group that matches fits criteria
        current_group = {}
        for group in groups:
            if group['exposure'] == exposure and group['gain'] == gain and group['offset'] == offset and group['filter'] == filter:
                current_group = group
                break
        if current_group == {}:
            #file does not cotain a matching group - create new group
            group = {}
            group['id'] = str(len(groups))
            group['index'] = last_line
            group['gain']  = gain
            group['offset'] = offset
            group['exposure'] = int(exposure)
            group['filter'] = filter
            print(group)
            groups.append(group)
            current_group = group
            lines.insert(last_line,'#GROUPID#'+group['id']+'\n')
            last_line = last_line + 1            
            lines.insert(last_line,'1\tdark\t' + rel_dark_cali_file  + '\n')
            last_line = last_line + 1
            lines.insert(last_line,'1\tflat\t' + rel_flat_cali_file  + '\n')
            last_line = last_line + 1


        for idx,line in enumerate(lines):
            if line[0] == 'C' or line[0] == 'D':                
                continue
            elif line[0] == '1' or line[0] == '0':
                if line[2] == 'l' and  rel_filename in line:
                    entry_found = True
                    break
            elif ( line[4] == '#WS#' ):
                break        

        if entry_found == False:
            line = '1\tlight\t' + rel_filename + '\n'
            lines.insert( current_group['index'] + 1,line)
            with open(dss_file_path, 'w') as f:
                for line in lines:
                    f.write(line)
#                if dss_file_path not in dss_file_list_set:
#                    dss_file_list_set.add(dss_file_path)
#                    dss_file_list.append(dss_file_path)
    
    os.chdir(curdir) # change directory back

    return dss_file_list
                
def stack_files(dss_files):
    print('### stack ###')
    with open('./config.json', 'r') as f:
        config = json.load(f)
    
    arguments = []


    command = config['dss_cl_location']

    arguments.append (command)                

    arguments.append('/S')
    arguments.append('/FITS')
    
    for dss_file in dss_files:
        arguments.append (dss_file)                
        subprocess.run(arguments)
        del arguments[-1]



###########################################
def reg_files(reg_all,dss_files):
    print('### register ###')
    with open('./config.json', 'r') as f:
        config = json.load(f)
    
    arguments = []


    command = config['dss_cl_location']

    arguments.append (command)                

    if reg_all == True:
        arguments.append('/R')
    else:
        arguments.append('/r')
    
    for dss_file in dss_files:
        arguments.append (dss_file)                
        subprocess.run(arguments)
        del arguments[-1]

###########################################
def copy_files(dir_from, dir_to, do_move):
    print('### COPY ###')

    target_files = []
    from_pattern = os.path.join(dir_from, '') + '*.fits'
    files = glob.glob(from_pattern)

    for f in files:
        filename = os.path.basename(f)
        if '_L_' in filename:
            filter = 'L'
        elif '_R_' in filename:
            filter = 'R'
        elif '_G_' in filename:
            filter = 'G'
        elif '_B_' in filename:
            filter = 'B'
        elif '_Ha_' in filename:
            filter = 'Ha'
        elif '_Oiii_' in filename:
            filter = 'Oiii'
        elif '_Sii_' in filename:
            filter = 'Sii'
        else:
            print('ERROR: Unknown Filter Pattern for File: ' + os.path.basename(f))
            continue

        #target_path = os.path.join(dir_to, '') + os.path.join('lights', '') + os.path.join(filter, '')
        target_path = os.path.join(dir_to, 'lights', filter, '')
        Path(target_path).mkdir(parents=True, exist_ok=True)

        target_file = target_path + os.path.basename(f)
        target_files.append(target_file)
        print(f + ' -> ' + target_file)

        shutil.copy(f, target_file)
        if do_move == True:
            os.remove(f)
    
    return target_files

if len(sys.argv) < 2:
    print('Not enough arguments')
    disp_help()
    sys.exit()

args = sys.argv
args.pop(0)

do_copy = False
do_reg  = False
do_regall = False
do_copy = False
do_move = False
do_add  = False
do_stack = False
do_add_super = False
to_path = ''
from_path = ''
file = []

parser = DefaultArgParser() #argparse.ArgumentParser()
parser.add_argument("source_dir", nargs='?', help="source directory for copy or move" )
parser.add_argument("project_dir", help="project directory where fits should be stored")
group = parser.add_mutually_exclusive_group()
group.add_argument("-m", "--move", help="move files from source folder to project folder",action="store_true")
group.add_argument("-c", "--copy", help="copy files from source folder to project folder",action="store_true")
parser.add_argument("-a", "--add", help="add files to (existing or new) dsslist file",action="store_true")
parser.add_argument("-l", "--super-l", help="create a SUPER_L file out of R, G, B, L",action="store_true")
parser.add_argument("-r", "--register", help="register all non-registered files in dssfiles of project folder",action="store_true")
parser.add_argument("-R", "--register-all", help="(re-)register all files in dssfiles of project folder",action="store_true")
parser.add_argument("-s", "--stack", help="(re-)stack all files in dssfiles of project folder",action="store_true")
args = parser.parse_args()


if args.move:
    do_move = True

if args.copy:
    do_copy = True

if args.add:
    do_add = True

if args.super_l:
    do_add_super = True

if args.register:
    do_reg = True

if args.register_all:
    do_regall = True

if args.stack:
    do_stack = True

if args.project_dir is not None:
    to_path   = args.project_dir
elif args.source_dir is not None:
    from_path   = args.source_dir

files = []

if do_copy == True or do_move == True:
    if from_path == '' or to_path == '':
        print('Please specify from and to path')
        parser.print_help( )
        sys.exit()
    
    files = copy_files(from_path, to_path, do_move)
else:
    if from_path != '':
        print('from_path')
        print('Please specify only target')
        parser.print_help( )
        sys.exit()

    with open('./config.json', 'r') as f:
        config = json.load(f)
    for filter in config["filters"]:
        from_pattern = os.path.join(to_path, 'lights', filter) + '\*.fits'
        print(from_pattern)
        files = files + glob.glob(from_pattern)


if do_add == True:    
    dss_files = add_files(to_path,files,False)
else:
    from_pattern = os.path.join(to_path, '') + '*.dssfilelist'
    dss_files = glob.glob(from_pattern)

if do_add_super == True:
    from_pattern = os.path.join(to_path, 'lights\R' ) + '\*.fits'
    super_files =  glob.glob(from_pattern)
    from_pattern = os.path.join(to_path, 'lights\G' ) + '\*.fits'
    super_files = super_files + glob.glob(from_pattern)
    from_pattern = os.path.join(to_path, 'lights\B' ) + '\*.fits'
    super_files = super_files + glob.glob(from_pattern)
    from_pattern = os.path.join(to_path, 'lights\L' ) + '\*.fits'
    super_files = super_files + glob.glob(from_pattern)

#    foldername   = os.path.basename(os.path.normpath(to_path))
#    dss_super_file = os.path.join(to_path, '') + foldername + '_SUPER.dssfilelist'
#    dss_files = dss_files + dss_super_file
#    dss_super_files = []
#    dss_super_files.append( dss_super_file )
    dss_files = dss_files + add_files(to_path,super_files,True)


if do_reg == True or do_regall == True:
    reg_files(do_regall, dss_files)

if do_stack == True:
    stack_files( dss_files, )    